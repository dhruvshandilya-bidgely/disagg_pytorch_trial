"""
Author - Mayank Sharan
Date - 19th Nov 2018
After the completion of the pipeline this function arranges the output in the format needed and returns as a dictionary
"""

# Import python packages

import copy
import logging
import numpy as np

# Import functions from within the project

from python3.config.Cgbdisagg import Cgbdisagg
from python3.config.pilot_constants import PilotConstants
from python3.config.pipeline_constants import GlobalConfigParams

from python3.utils.maths_utils.find_seq import find_seq

from python3.config.mappings.get_app_id import get_app_id

from python3.master_pipeline.post_pipeline_ops.handle_vip_user import handle_vip_user

from python3.utils.validate_output_schema import validate_appliance_profile_schema_for_billcycle


def populate_appliance_profile(disagg_input_object, disagg_output_object, empty_appliance_profile, logger, logger_pass):

    """
    Populate appliance profile after schema validation for each billcycle

    Parameters:
        disagg_input_object              (dict)              : Contains all inputs required to run the pipeline
        disagg_output_object             (dict)              : Contains all outputs generated by running the pipeline
        empty_appliance_profile          (dict)              : Initialized appliance profile dictionary
        logger                           (logger)            : Logger object
        logger_pass                      (dict)              : Contains all variables needed for logging

    Returns:
        appliance_profile_output         (dict)              : Final prepared and validated appliance profile
    """

    appliance_profile_filled = disagg_output_object.get('appliance_profile')

    appliance_profile_output = copy.deepcopy(empty_appliance_profile)

    # Writing appliance profiles for all required bill cycles

    appliance_profile_fill_bill_cycles = disagg_input_object.get("out_bill_cycles_by_module").get("app_profile")

    for bill_cycle_raw_idx in range(len(appliance_profile_fill_bill_cycles)):

        bc_start = appliance_profile_fill_bill_cycles[bill_cycle_raw_idx, 0]

        # validate appliance profile for this bill cycle

        valid_flag = validate_appliance_profile_schema_for_billcycle(disagg_output_object, bc_start, logger_pass)

        if valid_flag:

            appliance_profile_bc = appliance_profile_filled[bc_start]['profileList'][0]

            appliance_profile_output['profileList'].append(appliance_profile_bc)

            logger.info("Writing appliance profile for billcycle | %d " % bc_start)

        else:

            logger.error("Skipping writing appliance profile for billcycle | %d" % bc_start)

    return appliance_profile_output


def log_disagg_matrix(app_id_dict, bill_cycle_estimate, logger):

    """
    Utility to log the disagg output matrix

    Parameters:
        app_id_dict             (dict)                  : Appliance id information
        bill_cycle_estimate     (numpy.ndarray)         : appliance estimates at bill cycle level
        logger                  (logger)                : Logger object

    """

    # Log the disagg output matrix

    logger.info('Mapping of column number to appliance id is | %s', str(app_id_dict).replace('\n', ' '))

    for row_idx in range(bill_cycle_estimate.shape[0]):
        if row_idx < 9:
            logger.info('Bill cycle number %d  | %s', row_idx + 1,
                        str(list(map(str, bill_cycle_estimate[row_idx, :]))).replace('\n', ' '))
        else:
            logger.info('Bill cycle number %d | %s', row_idx + 1,
                        str(list(map(str, bill_cycle_estimate[row_idx, :]))).replace('\n', ' '))


def populate_tb_instance(column_idx, disagg_output_object, app_id, params_dict):

    """
    Populates tb instance dictionary for a given app id

    Parameters:
        column_idx          (int)               : The column in which the data for the appliance is present
        disagg_output_object(dict)              : Contains all outputs generated by running the pipeline
        app_id              (int)               : The appliance id for which the dict is to be prepared
        params_dict         (dict)              : Dictionary containing parameters used to populate the instance

    Returns:
        skip_bool           (bool)              : Boolean indicating if the entry should be skipped
        tb_instance         (dict)              : Dictionary containing time band outputs for appliance id
    """

    # Extract Parameters

    epoch_estimate = params_dict.get('epoch_estimate')
    hourly_estimate = params_dict.get('hourly_estimate')
    valid_idx = params_dict.get('valid_idx')
    valid_idx_hr = params_dict.get('valid_idx_hr')
    start_arr_hr = params_dict.get('start_arr_hr')
    end_arr_hr = params_dict.get('end_arr_hr')
    start_arr = params_dict.get('start_arr')
    end_arr = params_dict.get('end_arr')
    bc_start = params_dict.get('bc_start')
    bc_end = params_dict.get('bc_end')
    sampling_rate = params_dict.get('sampling_rate')

    # Initialize column name constants

    seq_val_idx = 0
    seq_start_idx = 1
    seq_end_idx = 2

    if column_idx in disagg_output_object.get('output_write_idx_map').get('va', []):

        # Prepare output for vacation

        # Extract value array

        value_arr = np.round(hourly_estimate[valid_idx_hr, column_idx], 5)

        # Check if all values are nan do not write

        non_nan_count = np.sum(np.logical_not(np.isnan(value_arr)))

        if non_nan_count == 0:
            return True, {}

        # Set all nans to 0 to avoid errors

        value_arr[np.isnan(value_arr)] = 0

        # Compress the data to write by merging together intervals with the same value

        val_seq_arr = find_seq(value_arr, min_seq_length=0)

        comp_start_arr = start_arr_hr[val_seq_arr[:, seq_start_idx].astype(int)]
        comp_end_arr = end_arr_hr[val_seq_arr[:, seq_end_idx].astype(int)]
        comp_val_arr = val_seq_arr[:, seq_val_idx]

        tb_instance = {
            "appId": app_id,
            "start": bc_start,
            "end": bc_end,
            "granuality": Cgbdisagg.SEC_IN_HOUR,
            "tbStartList": comp_start_arr.tolist(),
            "tbEndList": comp_end_arr.tolist(),
            "tbValues": comp_val_arr.tolist()
        }

    else:

        # Extract value array

        value_arr = np.round(epoch_estimate[valid_idx, column_idx], 5)

        # Check if all values are nan do not write

        non_nan_count = np.sum(np.logical_not(np.isnan(value_arr)))

        if non_nan_count == 0:
            return True, {}

        # Set all nans to 0 to avoid errors

        value_arr[np.isnan(value_arr)] = 0

        # Compress the data to write by merging together intervals with the same value

        val_seq_arr = find_seq(value_arr, min_seq_length=0)

        comp_start_arr = start_arr[val_seq_arr[:, seq_start_idx].astype(int)]
        comp_end_arr = end_arr[val_seq_arr[:, seq_end_idx].astype(int)]
        comp_val_arr = val_seq_arr[:, seq_val_idx]

        tb_instance = {
            "appId": app_id,
            "start": bc_start,
            "end": bc_end,
            "granuality": sampling_rate,
            "tbStartList": comp_start_arr.tolist(),
            "tbEndList": comp_end_arr.tolist(),
            "tbValues": comp_val_arr.tolist()
        }

    return False, tb_instance


def prepare_time_band_disagg(disagg_input_object, disagg_output_object, epoch_estimate, app_id_dict, pilot_id, hybrid_v2_enable_flag):

    """
    Prepares timestamp level output objects containing disagg values

    Parameters:
        disagg_input_object (dict)              : Contains all inputs required to run the pipeline
        disagg_output_object(dict)              : Contains all outputs generated by running the pipeline
        app_id_dict         (dict)              : Contains mapping of estimate col idx to appliance id

    Returns:
        tb_output           (list)              : List of dictionaries containing all time band outputs
    """

    # Initialize column name constants

    ts_col_idx = 0
    bc_start_idx = 0
    bc_end_idx = 1

    # Initialize the tb output list

    tb_output = []

    # Extract epoch estimate at the timestamp

    num_columns = epoch_estimate.shape[1]

    # Down sample each appliance output to hour level

    sampling_rate = disagg_input_object.get('config').get('sampling_rate')

    # Initialize out bill cycles

    out_bill_cycles = disagg_input_object.get('out_bill_cycles_by_module').get('disagg_tou')
    num_out_billing_cycles = out_bill_cycles.shape[0]

    # Extract appliances to write TOU for

    tou_out_app_id_list = None

    if disagg_input_object.get('gb_pipeline_event').get('disaggRunMode') is not None:
        disagg_run_mode = disagg_input_object.get('gb_pipeline_event').get('disaggRunMode').get('applianceDisaggRunMode')
        tou_out_app_id_list = disagg_run_mode.get('timebandDisaggModeData').get('applianceIds')

    # Extract hourly data for vacation

    input_data = copy.deepcopy(disagg_input_object.get('input_data'))

    bill_cycle_hourly_idx = (input_data[:, Cgbdisagg.INPUT_BILL_CYCLE_IDX] -
                             input_data[0, Cgbdisagg.INPUT_BILL_CYCLE_IDX]) // Cgbdisagg.SEC_IN_HOUR

    epoch_hourly_idx = bill_cycle_hourly_idx + (input_data[:, Cgbdisagg.INPUT_EPOCH_IDX] -
                                                input_data[:, Cgbdisagg.INPUT_BILL_CYCLE_IDX]) // Cgbdisagg.SEC_IN_HOUR

    _, epoch_hourly_unique_idx = np.unique(epoch_hourly_idx, axis=0, return_index=True)

    hourly_estimate = epoch_estimate[epoch_hourly_unique_idx, :]

    # In case the first timestamp is out of sync in granularity adjust

    first_point_mod = (hourly_estimate[0, 0] - input_data[0, Cgbdisagg.INPUT_BILL_CYCLE_IDX]) % Cgbdisagg.SEC_IN_HOUR

    if first_point_mod > 0:
        hourly_estimate[0, 0] = hourly_estimate[0, 0] - first_point_mod

    # For each appliance and for each billing cycle prepare the tb output dictionary

    for bill_cycle_idx in range(num_out_billing_cycles):

        # Identify valid indices for the current bill cycle

        bc_start = int(out_bill_cycles[bill_cycle_idx, bc_start_idx])
        bc_end = int(out_bill_cycles[bill_cycle_idx, bc_end_idx])

        valid_idx = np.logical_and(epoch_estimate[:, ts_col_idx] >= bc_start, epoch_estimate[:, ts_col_idx] < bc_end)

        valid_idx_hr = np.logical_and(hourly_estimate[:, ts_col_idx] >= bc_start,
                                      hourly_estimate[:, ts_col_idx] < bc_end)

        # Prepare start and end array for usage

        start_arr = epoch_estimate[valid_idx, ts_col_idx]
        end_arr = start_arr + sampling_rate

        start_arr_hr = hourly_estimate[valid_idx_hr, ts_col_idx]
        end_arr_hr = start_arr_hr + Cgbdisagg.SEC_IN_HOUR

        for column_idx in range(1, num_columns):

            # Extract app id corresponding to the column

            app_id = app_id_dict.get(column_idx)

            # Check if TOU for this appliance has to be written or not

            if (tou_out_app_id_list is not None) and (app_id not in tou_out_app_id_list):
                continue

            if (app_id == -1) or check_output_writing_skip_bool(pilot_id, app_id_dict, hybrid_v2_enable_flag, column_idx):
                continue

            params_dict = {
                'epoch_estimate': epoch_estimate,
                'hourly_estimate': hourly_estimate,
                'valid_idx': valid_idx,
                'valid_idx_hr': valid_idx_hr,
                'start_arr_hr': start_arr_hr,
                'end_arr_hr': end_arr_hr,
                'start_arr': start_arr,
                'end_arr': end_arr,
                'bc_start': bc_start,
                'bc_end': bc_end,
                'sampling_rate': sampling_rate,
            }

            skip_bool, tb_instance = populate_tb_instance(column_idx, disagg_output_object, app_id, params_dict)

            if skip_bool:
                continue

            tb_output.append(tb_instance)

    return tb_output


def check_output_writing_skip_bool(pilot_id, app_id_dict, hybrid_v2_enabled_flag, column_idx):

    """
    Prepares timestamp level output objects containing disagg values

    Parameters:
        disagg_input_object (dict)              : Contains all inputs required to run the pipeline
        disagg_output_object(dict)              : Contains all outputs generated by running the pipeline
        app_id_dict         (dict)              : Contains mapping of estimate col idx to appliance id

    Returns:
        tb_output           (list)              : List of dictionaries containing all time band outputs
    """

    #  checking whether to disable pp results posting from disagg pipeline and later enable posting in itemization pipeline

    output_skip_bool = ((app_id_dict[column_idx] == 2) and
                        ('pp' in GlobalConfigParams.disagg_postprocess_enabled_app) and
                        (pilot_id not in PilotConstants.HYBRID_PP_DISABLED_PILOTS))

    #  checking whether to disable ev results posting from disagg pipeline and later enable posting in itemization pipeline

    output_skip_bool = output_skip_bool or ((app_id_dict[column_idx] == 18) and
                                            ('ev' in GlobalConfigParams.disagg_postprocess_enabled_app) and
                                            (pilot_id not in PilotConstants.HYBRID_EV_DISABLED_PILOTS))

    #  checking whether to disable wh results posting from disagg pipeline and later enable posting in itemization pipeline

    output_skip_bool = output_skip_bool or ((app_id_dict[column_idx] == 7) and
                                            ('wh' in GlobalConfigParams.disagg_postprocess_enabled_app) and
                                            (pilot_id not in PilotConstants.HYBRID_WH_DISABLED_PILOTS))

    #  checking whether to disable hvac results posting from disagg pipeline and later enable posting in itemization pipeline

    output_skip_bool = output_skip_bool or ((app_id_dict[column_idx] in [3, 4]) and
                                            ('hvac' in GlobalConfigParams.disagg_postprocess_enabled_app) and
                                            (pilot_id not in PilotConstants.HYBRID_HVAC_DISABLED_PILOTS))

    output_skip_bool = output_skip_bool or ((app_id_dict[column_idx] == 99) and
                                            ('others' in GlobalConfigParams.disagg_postprocess_enabled_app))

    output_skip_bool = output_skip_bool or (hybrid_v2_enabled_flag and app_id_dict[column_idx] != 16)

    return output_skip_bool


def populate_gb_monthly_output(app_id_dict, column_idx, out_bill_cycles, bill_cycle_raw_idx, value):
    """
    Parameters:
        app_id_dict         (dict)      : Contains mapping of app ids
        column_idx          (dict)      : Contains mapping of column indexes
        out_bill_cycles     (np.ndarray): Array of out billing cycles
        bill_cycle_raw_idx  (int)       : Contains current bill cycle raw index
        value               (float)     : Contains bill cycle level consumption value

    Return:
        output_instance     (dict)      : Dictionary containing gb monthly output instance
    """
    output_instance = {
        "appId": app_id_dict[column_idx],
        "start": int(out_bill_cycles[bill_cycle_raw_idx, 0]),
        "end": int(out_bill_cycles[bill_cycle_raw_idx, 1]),
        "value": value,
        "tb": "null",
        "weekday": "null",
        "detectionConfidence": 1,
        "estimationConfidence": 1
    }

    return output_instance


def prepare_appid_dict(app_name_list, output_write_idx_map, app_id_dict):
    """
    Function to return the appid dictionary

    Parameters:
        app_name_list           (list): list of appliances
        output_write_idx_map    (dict): contains writing indexes corresponding to app ids
        app_id_dict             (dict): contains mapping of app name to app id

    Returns:
        app_id_dict             (dict): contains mapping of app name to app id
    """

    for app_name in app_name_list:
        if app_name == 'hvac' or app_name == 'hvac_smb':
            col_idx = output_write_idx_map.get(app_name)
            app_id_dict[col_idx[0]] = get_app_id('ac')
            app_id_dict[col_idx[1]] = get_app_id('sh')
        elif app_name == 'va':
            col_idx = output_write_idx_map.get(app_name)
            app_id_dict[col_idx[0]] = get_app_id('va')
            app_id_dict[col_idx[1]] = get_app_id('vad')
        elif app_name == 'ao' or app_name == 'ao_smb':
            app_id_dict[output_write_idx_map.get(app_name)] = get_app_id('ao')
        else:
            app_id_dict[output_write_idx_map.get(app_name)] = get_app_id(app_name)

    return app_id_dict


def get_gb_monthly_output(monthly_output_maker, pilot_id, hybrid_v2_enable_flag):

    """
    Function to return the gb monthly output payload

    Parameters:
        monthly_output_maker    (dict)  : Contains objects needed to prepare gb monthly output instances

    Returns:
        gb_monthly_output       (list)  : Contains gb monthly output in list form for each billing cycle
    """

    out_bill_cycles = monthly_output_maker.get('out_bill_cycles')
    bill_cycle_raw_idx = monthly_output_maker.get('bill_cycle_raw_idx')
    bill_cycle_estimate = monthly_output_maker.get('bill_cycle_estimate')
    num_columns = monthly_output_maker.get('num_columns')
    app_id_dict = monthly_output_maker.get('app_id_dict')
    gb_monthly_output = monthly_output_maker.get('gb_monthly_output')

    app_id_dict[len(bill_cycle_estimate[0])-1] = get_app_id('others')

    bc_start = out_bill_cycles[bill_cycle_raw_idx, 0]
    bill_cycle_idx = np.where(bill_cycle_estimate[:, 0] == bc_start)[0][0]

    for column_idx in range(1, num_columns):

        value = bill_cycle_estimate[bill_cycle_idx, column_idx]

        if np.isnan(value) or (value == 0) or (app_id_dict[column_idx] == -1):
            continue

        disable_posting_flag = disable_postprocessing_app_results_posting(app_id_dict, column_idx, pilot_id, hybrid_v2_enable_flag)

        if disable_posting_flag:
            continue

        output_instance = populate_gb_monthly_output(app_id_dict, column_idx, out_bill_cycles,
                                                     bill_cycle_raw_idx, value)

        gb_monthly_output.append(output_instance)

    return gb_monthly_output


def prepare_disagg_aer_results(disagg_input_object, disagg_output_object):

    """
    Parameters:
        disagg_input_object (dict)              : Contains all inputs required to run the pipeline
        disagg_output_object(dict)              : Contains all outputs generated by running the pipeline

    Returns:
        api_disagg_output   (dict)              : Contains all disagg outputs in the format to post using the API
    """

    # Initialize the logger

    logger_base = disagg_input_object.get('logger').getChild('prepare_disagg_aer_results')
    logger = logging.LoggerAdapter(logger_base, disagg_input_object.get('logging_dict'))

    logger_pass = {
        'logger_base': logger_base,
        'logging_dict': disagg_input_object.get('logging_dict'),
    }

    # Handling the VIP user use case
    disagg_output_object = handle_vip_user(disagg_input_object, disagg_output_object)
    priority = disagg_input_object.get('config').get('priority')

    if priority:
        pr_flag = "true"
    else:
        pr_flag = "false"

    # Initialize empty appliance profile

    empty_appliance_profile = {
        "version": "v1",
        "profileList": []
    }

    trigger_id = disagg_input_object.get('config').get('trigger_id')
    trigger_name = disagg_input_object.get('config').get('trigger_name')

    # In case where trigger id and trigger name are absent in disagg queue messages,
    # None values will be posted as default values in output payload

    if trigger_id == '':
        trigger_id = None

    if trigger_name == '':
        trigger_name = None

    # Storetimebandincassandra check
    storeTimebandInCassandra = disagg_input_object.get('store_tb_in_cassandra')

    if storeTimebandInCassandra is None:
        storeTimebandInCassandra = False

    # Initialize the dictionary for output in the format as needed

    api_disagg_output = {

        "hybridMetaData": {
            "runHybridV2": False,
            "hybridAppIds": []
        },

        "gbInputMessage": {
            "userId": disagg_input_object.get('config').get('uuid'),
            "homeOrdinal": 1,
            "pilotId": disagg_input_object.get('config').get('pilot_id'),
            "start": int(disagg_input_object.get('gb_pipeline_event').get('start')),
            "end": int(disagg_input_object.get('gb_pipeline_event').get('end')),
            "disaggMode": disagg_input_object.get('gb_pipeline_event').get('disaggMode'),
            "mode": disagg_input_object.get('gb_pipeline_event').get('mode'),
            "isPriority": pr_flag,
            "triggerId": trigger_id,
            "triggerName": trigger_name,
            "storeTimebandInCassandra": storeTimebandInCassandra,
        },
        "gbMonthlyOutput": [],
        "gbOutputStatus": {},
        "gbInputDataQuality": {
            "constantConsPerc": disagg_input_object.get('data_quality_metrics').get('constant_cons_perc'),
            "missingDataPerc": disagg_input_object.get('data_quality_metrics').get('missing_data_perc'),
            "presentSunrisePerc": disagg_input_object.get('data_quality_metrics').get('present_sunrise_perc'),
            "presentSunsetPerc": disagg_input_object.get('data_quality_metrics').get('present_sunset_perc'),
            "presentTempPerc": disagg_input_object.get('data_quality_metrics').get('present_temp_perc'),
            "validConsPerc": disagg_input_object.get('data_quality_metrics').get('valid_cons_perc'),
            "zeroConsPerc": disagg_input_object.get('data_quality_metrics').get('zero_cons_perc')
        },
        "gbTBOutput": [],
        "applianceProfile": empty_appliance_profile
    }

    # Get variables ready to write gbMonthlyOutput

    output_write_idx_map = disagg_output_object.get('output_write_idx_map')
    app_name_list = list(output_write_idx_map.keys())

    app_id_dict = {}

    # Generate a mapping from column number to corresponding app id with which backend will save the results

    app_id_dict = prepare_appid_dict(app_name_list, output_write_idx_map, app_id_dict)

    # Populate gbOutputStatus

    disagg_metrics_dict = disagg_output_object['disagg_metrics']

    output_status_dict = {
        "exitCode": disagg_metrics_dict.get('aer_pipeline').get('exit_code'),
        "errorCodes": disagg_metrics_dict.get('aer_pipeline').get('error_codes'),
        "processingTime": np.round(1000 * disagg_metrics_dict.get('aer_pipeline').get('runtime'), 3),
        "gbAppStatus": []
    }

    gb_app_status_list = []

    for app_name in app_name_list:
        if disagg_metrics_dict.get(app_name) is not None:
            status_instance = {
                "appId": get_app_id(app_name),
                "exitCode": disagg_metrics_dict.get(app_name).get('exit_status').get('exit_code'),
                "processingTime": np.round(1000 * disagg_metrics_dict.get(app_name).get('time'), 3)
            }
            gb_app_status_list.append(status_instance)

    output_status_dict['gbAppStatus'] = gb_app_status_list
    api_disagg_output['gbOutputStatus'] = output_status_dict

    #Prepare others output

    billing_cycle_list = disagg_input_object.get("input_data")[:, Cgbdisagg.INPUT_BILL_CYCLE_IDX]
    out_bill_cycles = disagg_input_object.get('out_bill_cycles_by_module').get('disagg_bc')

    # Populate gbMonthlyOutput
    bill_cycle_estimate = copy.deepcopy(np.round(disagg_output_object.get('bill_cycle_estimate'), decimals=2))
    epoch_estimate = copy.deepcopy(disagg_output_object.get('epoch_estimate'))

    bc_level_others, ts_level_others = \
        calculate_others(disagg_input_object, output_write_idx_map, billing_cycle_list, epoch_estimate, bill_cycle_estimate)

    bill_cycle_estimate = np.hstack((bill_cycle_estimate, bc_level_others[:, None]))
    epoch_estimate =  np.hstack((epoch_estimate, ts_level_others[:, None]))

    num_columns = bill_cycle_estimate.shape[1]

    num_out_billing_cycles = out_bill_cycles.shape[0]

    pilot_id = disagg_input_object.get('config').get('pilot_id')

    hybrid_v2_enable_flag = disagg_input_object.get('config').get('enable_hybrid_v2')

    gb_monthly_output = []

    for bill_cycle_raw_idx in range(num_out_billing_cycles):

        monthly_output_maker = {'out_bill_cycles': out_bill_cycles,
                                'bill_cycle_raw_idx': bill_cycle_raw_idx,
                                'bill_cycle_estimate': bill_cycle_estimate,
                                'num_columns' : num_columns,
                                'app_id_dict' : app_id_dict,
                                'disagg_output_object' : disagg_output_object,
                                'gb_monthly_output' : gb_monthly_output}

        gb_monthly_output = get_gb_monthly_output(monthly_output_maker, pilot_id, hybrid_v2_enable_flag)

    api_disagg_output['gbMonthlyOutput'] = gb_monthly_output
    api_disagg_output['gbTBOutput'] = prepare_time_band_disagg(disagg_input_object, disagg_output_object, epoch_estimate, app_id_dict, pilot_id, hybrid_v2_enable_flag)      # utils

    appliance_profile_output = populate_appliance_profile(disagg_input_object, disagg_output_object,
                                                          empty_appliance_profile, logger, logger_pass)

    api_disagg_output['applianceProfile'] = appliance_profile_output

    # Call the function to log the output matrix

    log_disagg_matrix(app_id_dict, bill_cycle_estimate, logger)

    return api_disagg_output


def calculate_others(disagg_input_object, output_write_idx_map, billing_cycle_list, epoch_estimate, bill_cycle_estimate):

    """
    This function is used to calculate ts level and bill cycle level others
    Parameters:
        disagg_input_object     (dict)                      : Contains all inputs required to run the pipeline
        output_write_idx_map    (dict)                      : appliance index map
        billing_cycle_list      (np.ndarray)                : list of target billing cycles
        epoch_estimate          (np.ndarray)                : ts level disagg output
        bill_cycle_estimate     (np.ndarray)                : bc level disagg output

    Returns:
        bc_level_others         (np.ndarray)                : bc level others output
        ts_level_others         (np.ndarray)                : ts level others output
    """

    if disagg_input_object.get("input_data_without_outlier_removal") is None:
        disagg_input_data = np.zeros(len(epoch_estimate))
    else:
        disagg_input_data = copy.deepcopy(disagg_input_object.get("input_data_without_outlier_removal")[:, Cgbdisagg.INPUT_CONSUMPTION_IDX])

    out_bill_cycles = bill_cycle_estimate[:, 0]

    bc_level_input_data = np.zeros(len(out_bill_cycles))

    for i in range(len(out_bill_cycles)):
        bc_level_input_data[i] = np.sum(disagg_input_data[billing_cycle_list == out_bill_cycles[i]])

    bc_level_others = bc_level_input_data
    ts_level_others = disagg_input_data

    disagg_app_ids = []

    res_true_disagg_app_list = GlobalConfigParams.residential_true_disagg_app_list

    for app in res_true_disagg_app_list:
        disagg_app_ids = np.append(disagg_app_ids, output_write_idx_map.get(app))

    disagg_app_ids = disagg_app_ids.astype(int)

    bc_level_others = bc_level_others - np.nansum(bill_cycle_estimate[:, disagg_app_ids], axis=1)
    ts_level_others = ts_level_others - np.nansum(epoch_estimate[:, disagg_app_ids], axis=1)

    return bc_level_others, ts_level_others


def disable_postprocessing_app_results_posting(app_id_dict, column_idx, pilot_id, hybrid_v2_enable_flag):

    """
    this function determines whether the appliance output should be posted from disagg pipeline or itemization pipeline

    Parameters:
        app_id_dict             (dict)           : appliance id dict
        column_idx              (int)            : column index of the appliance being considered for results preparation
        pilot_id                (int)            : pilot id
    Returns:
        disable_posting         (bool)           : If this flag is true, results of the appliance will be posted from itemization pipeline
    """

    disable_posting = False

    # HYBRID_PP_DISABLED_PILOTS - pilots for which pp postprocessing is disabled

    if (app_id_dict[column_idx] == 2) and \
            ('pp' in GlobalConfigParams.disagg_postprocess_enabled_app) and \
            (pilot_id not in PilotConstants.HYBRID_PP_DISABLED_PILOTS):
        disable_posting = True

    # HYBRID_EV_DISABLED_PILOTS - pilots for which ev postprocessing is disabled

    if (app_id_dict[column_idx] == 18) and \
            ('ev' in GlobalConfigParams.disagg_postprocess_enabled_app) and \
            (pilot_id not in PilotConstants.HYBRID_EV_DISABLED_PILOTS):
        disable_posting = True

    # HYBRID_WH_DISABLED_PILOTS - pilots for which WH postprocessing is disabled

    if (app_id_dict[column_idx] == 7) and \
            ('wh' in GlobalConfigParams.disagg_postprocess_enabled_app) and \
            (pilot_id not in PilotConstants.HYBRID_WH_DISABLED_PILOTS):
        disable_posting = True

    # HYBRID_HVAC_DISABLED_PILOTS - pilots for which HVAC postprocessing is disabled

    if (app_id_dict[column_idx] in [3, 4]) and \
            ('hvac' in GlobalConfigParams.disagg_postprocess_enabled_app) and \
            (pilot_id not in PilotConstants.HYBRID_HVAC_DISABLED_PILOTS):
        disable_posting = True

    if (app_id_dict[column_idx] == 99) and \
            ('others' in GlobalConfigParams.disagg_postprocess_enabled_app):
        disable_posting = True

    disable_posting = disable_posting or \
                      (hybrid_v2_enable_flag and
                       app_id_dict[column_idx] not in [get_app_id('solar'), get_app_id('va'), get_app_id('vad')])

    return disable_posting
